{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.preprocess import clean_str, build_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import CNN1d, binary_accuracy, train, evaluate, epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import TabularDataset, Field, LabelField, BucketIterator\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TEXT = Field(sequential = True, # text: sequential data\n",
    "             tokenize = str.split, \n",
    "             batch_first = True, \n",
    "             fix_length = 56, # padding size: max length of data text\n",
    "             lower = True)\n",
    "LABEL = LabelField(sequential = False,\n",
    "                   dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the kfold 0 data\n",
      "save the kfold 1 data\n",
      "save the kfold 2 data\n",
      "save the kfold 3 data\n",
      "save the kfold 4 data\n",
      "save the kfold 5 data\n",
      "save the kfold 6 data\n",
      "save the kfold 7 data\n",
      "save the kfold 8 data\n",
      "save the kfold 9 data\n"
     ]
    }
   ],
   "source": [
    "# make dataset for 10-fold\n",
    "data_dir = './preprocess'\n",
    "train_paths, val_paths = build_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "test_acc_lists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastText' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ba0fcc1e4e85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'FastText' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import FastText\n",
    "vectors=FastText(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 0\n",
      "\tEpoch: 01 | Epoch Time: 1m 1s\n",
      "\t\tTrain Loss: 0.588 | Train Acc: 67.86%\n",
      "\t\tTest. Loss: 0.539 |  Val. Acc: 73.45%\n",
      "\tEpoch: 02 | Epoch Time: 1m 0s\n",
      "\t\tTrain Loss: 0.470 | Train Acc: 77.17%\n",
      "\t\tTest. Loss: 0.500 |  Val. Acc: 74.82%\n",
      "\tEpoch: 03 | Epoch Time: 1m 0s\n",
      "\t\tTrain Loss: 0.400 | Train Acc: 81.99%\n",
      "\t\tTest. Loss: 0.534 |  Val. Acc: 76.09%\n",
      "\tEpoch: 04 | Epoch Time: 1m 0s\n",
      "\t\tTrain Loss: 0.342 | Train Acc: 85.15%\n",
      "\t\tTest. Loss: 0.498 |  Val. Acc: 77.36%\n",
      "\tEpoch: 05 | Epoch Time: 1m 11s\n",
      "\t\tTrain Loss: 0.273 | Train Acc: 89.00%\n",
      "\t\tTest. Loss: 0.547 |  Val. Acc: 76.36%\n",
      "\tEpoch: 06 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.212 | Train Acc: 91.51%\n",
      "\t\tTest. Loss: 0.574 |  Val. Acc: 78.36%\n",
      "\tEpoch: 07 | Epoch Time: 1m 16s\n",
      "\t\tTrain Loss: 0.149 | Train Acc: 94.33%\n",
      "\t\tTest. Loss: 0.638 |  Val. Acc: 77.55%\n",
      "\tEpoch: 08 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.115 | Train Acc: 95.89%\n",
      "\t\tTest. Loss: 0.688 |  Val. Acc: 75.45%\n",
      "\tEpoch: 09 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.065 | Train Acc: 98.05%\n",
      "\t\tTest. Loss: 0.823 |  Val. Acc: 76.18%\n",
      "\tEpoch: 10 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.040 | Train Acc: 98.93%\n",
      "\t\tTest. Loss: 0.860 |  Val. Acc: 76.36%\n",
      "============== last test accuracy: 0.7754545374350115\n",
      "\n",
      "kfold 1\n",
      "\tEpoch: 01 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.591 | Train Acc: 67.64%\n",
      "\t\tTest. Loss: 0.476 |  Val. Acc: 78.18%\n",
      "\tEpoch: 02 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.469 | Train Acc: 77.64%\n",
      "\t\tTest. Loss: 0.420 |  Val. Acc: 80.55%\n",
      "\tEpoch: 03 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.412 | Train Acc: 81.15%\n",
      "\t\tTest. Loss: 0.413 |  Val. Acc: 80.91%\n",
      "\tEpoch: 04 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.343 | Train Acc: 84.97%\n",
      "\t\tTest. Loss: 0.523 |  Val. Acc: 75.82%\n",
      "\tEpoch: 05 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.280 | Train Acc: 88.12%\n",
      "\t\tTest. Loss: 0.431 |  Val. Acc: 81.45%\n",
      "\tEpoch: 06 | Epoch Time: 1m 22s\n",
      "\t\tTrain Loss: 0.217 | Train Acc: 91.41%\n",
      "\t\tTest. Loss: 0.650 |  Val. Acc: 74.82%\n",
      "\tEpoch: 07 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.158 | Train Acc: 93.93%\n",
      "\t\tTest. Loss: 0.486 |  Val. Acc: 76.82%\n",
      "\tEpoch: 08 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.105 | Train Acc: 96.45%\n",
      "\t\tTest. Loss: 0.499 |  Val. Acc: 81.27%\n",
      "\tEpoch: 09 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.072 | Train Acc: 97.53%\n",
      "\t\tTest. Loss: 0.572 |  Val. Acc: 81.36%\n",
      "\tEpoch: 10 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.054 | Train Acc: 98.31%\n",
      "\t\tTest. Loss: 0.653 |  Val. Acc: 79.82%\n",
      "============== last test accuracy: 0.8145454580133612\n",
      "\n",
      "kfold 2\n",
      "\tEpoch: 01 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.588 | Train Acc: 67.58%\n",
      "\t\tTest. Loss: 0.532 |  Val. Acc: 71.67%\n",
      "\tEpoch: 02 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.478 | Train Acc: 77.06%\n",
      "\t\tTest. Loss: 0.444 |  Val. Acc: 78.33%\n",
      "\tEpoch: 03 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.400 | Train Acc: 81.90%\n",
      "\t\tTest. Loss: 0.424 |  Val. Acc: 80.91%\n",
      "\tEpoch: 04 | Epoch Time: 1m 22s\n",
      "\t\tTrain Loss: 0.343 | Train Acc: 84.83%\n",
      "\t\tTest. Loss: 0.427 |  Val. Acc: 81.06%\n",
      "\tEpoch: 05 | Epoch Time: 1m 17s\n",
      "\t\tTrain Loss: 0.276 | Train Acc: 88.09%\n",
      "\t\tTest. Loss: 0.449 |  Val. Acc: 80.00%\n",
      "\tEpoch: 06 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.213 | Train Acc: 91.61%\n",
      "\t\tTest. Loss: 0.450 |  Val. Acc: 81.79%\n",
      "\tEpoch: 07 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.169 | Train Acc: 93.37%\n",
      "\t\tTest. Loss: 0.478 |  Val. Acc: 80.45%\n",
      "\tEpoch: 08 | Epoch Time: 1m 23s\n",
      "\t\tTrain Loss: 0.120 | Train Acc: 96.03%\n",
      "\t\tTest. Loss: 0.488 |  Val. Acc: 82.06%\n",
      "\tEpoch: 09 | Epoch Time: 1m 31s\n",
      "\t\tTrain Loss: 0.083 | Train Acc: 97.45%\n",
      "\t\tTest. Loss: 0.564 |  Val. Acc: 82.03%\n",
      "\tEpoch: 10 | Epoch Time: 1m 30s\n",
      "\t\tTrain Loss: 0.054 | Train Acc: 98.33%\n",
      "\t\tTest. Loss: 0.593 |  Val. Acc: 82.73%\n",
      "============== last test accuracy: 0.8272727213122628\n",
      "\n",
      "kfold 3\n",
      "\tEpoch: 01 | Epoch Time: 1m 24s\n",
      "\t\tTrain Loss: 0.589 | Train Acc: 67.28%\n",
      "\t\tTest. Loss: 0.560 |  Val. Acc: 70.01%\n",
      "\tEpoch: 02 | Epoch Time: 1m 30s\n",
      "\t\tTrain Loss: 0.467 | Train Acc: 77.58%\n",
      "\t\tTest. Loss: 0.483 |  Val. Acc: 77.42%\n",
      "\tEpoch: 03 | Epoch Time: 1m 29s\n",
      "\t\tTrain Loss: 0.404 | Train Acc: 81.33%\n",
      "\t\tTest. Loss: 0.684 |  Val. Acc: 69.39%\n",
      "\tEpoch: 04 | Epoch Time: 1m 30s\n",
      "\t\tTrain Loss: 0.345 | Train Acc: 84.62%\n",
      "\t\tTest. Loss: 0.530 |  Val. Acc: 76.58%\n",
      "\tEpoch: 05 | Epoch Time: 1m 31s\n",
      "\t\tTrain Loss: 0.283 | Train Acc: 87.90%\n",
      "\t\tTest. Loss: 0.482 |  Val. Acc: 78.06%\n",
      "\tEpoch: 06 | Epoch Time: 1m 28s\n",
      "\t\tTrain Loss: 0.213 | Train Acc: 91.73%\n",
      "\t\tTest. Loss: 0.980 |  Val. Acc: 69.39%\n",
      "\tEpoch: 07 | Epoch Time: 1m 27s\n",
      "\t\tTrain Loss: 0.160 | Train Acc: 94.06%\n",
      "\t\tTest. Loss: 0.515 |  Val. Acc: 79.40%\n",
      "\tEpoch: 08 | Epoch Time: 1m 27s\n",
      "\t\tTrain Loss: 0.111 | Train Acc: 96.00%\n",
      "\t\tTest. Loss: 0.964 |  Val. Acc: 72.71%\n",
      "\tEpoch: 09 | Epoch Time: 1m 26s\n",
      "\t\tTrain Loss: 0.080 | Train Acc: 97.34%\n",
      "\t\tTest. Loss: 0.650 |  Val. Acc: 79.01%\n",
      "\tEpoch: 10 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.066 | Train Acc: 97.83%\n",
      "\t\tTest. Loss: 1.047 |  Val. Acc: 73.99%\n",
      "============== last test accuracy: 0.7871957648368109\n",
      "\n",
      "kfold 4\n",
      "\tEpoch: 01 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.584 | Train Acc: 67.58%\n",
      "\t\tTest. Loss: 0.478 |  Val. Acc: 77.39%\n",
      "\tEpoch: 02 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.472 | Train Acc: 77.37%\n",
      "\t\tTest. Loss: 0.449 |  Val. Acc: 77.29%\n",
      "\tEpoch: 03 | Epoch Time: 1m 17s\n",
      "\t\tTrain Loss: 0.399 | Train Acc: 81.86%\n",
      "\t\tTest. Loss: 0.483 |  Val. Acc: 76.40%\n",
      "\tEpoch: 04 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.342 | Train Acc: 85.16%\n",
      "\t\tTest. Loss: 0.430 |  Val. Acc: 79.12%\n",
      "\tEpoch: 05 | Epoch Time: 1m 15s\n",
      "\t\tTrain Loss: 0.277 | Train Acc: 88.16%\n",
      "\t\tTest. Loss: 0.427 |  Val. Acc: 80.85%\n",
      "\tEpoch: 06 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.214 | Train Acc: 91.10%\n",
      "\t\tTest. Loss: 0.441 |  Val. Acc: 80.96%\n",
      "\tEpoch: 07 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.150 | Train Acc: 94.61%\n",
      "\t\tTest. Loss: 0.564 |  Val. Acc: 78.32%\n",
      "\tEpoch: 08 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.108 | Train Acc: 96.14%\n",
      "\t\tTest. Loss: 0.498 |  Val. Acc: 80.87%\n",
      "\tEpoch: 09 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.075 | Train Acc: 97.40%\n",
      "\t\tTest. Loss: 0.656 |  Val. Acc: 78.38%\n",
      "\tEpoch: 10 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.054 | Train Acc: 98.48%\n",
      "\t\tTest. Loss: 0.608 |  Val. Acc: 80.25%\n",
      "============== last test accuracy: 0.8094197267835791\n",
      "\n",
      "kfold 5\n",
      "\tEpoch: 01 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.588 | Train Acc: 67.31%\n",
      "\t\tTest. Loss: 0.494 |  Val. Acc: 74.82%\n",
      "\tEpoch: 02 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.473 | Train Acc: 77.42%\n",
      "\t\tTest. Loss: 0.474 |  Val. Acc: 77.18%\n",
      "\tEpoch: 03 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.411 | Train Acc: 80.72%\n",
      "\t\tTest. Loss: 0.471 |  Val. Acc: 77.71%\n",
      "\tEpoch: 04 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.337 | Train Acc: 85.22%\n",
      "\t\tTest. Loss: 0.442 |  Val. Acc: 80.02%\n",
      "\tEpoch: 05 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.270 | Train Acc: 88.51%\n",
      "\t\tTest. Loss: 0.460 |  Val. Acc: 78.51%\n",
      "\tEpoch: 06 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.210 | Train Acc: 91.64%\n",
      "\t\tTest. Loss: 0.789 |  Val. Acc: 71.87%\n",
      "\tEpoch: 07 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.148 | Train Acc: 94.71%\n",
      "\t\tTest. Loss: 0.624 |  Val. Acc: 77.89%\n",
      "\tEpoch: 08 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.101 | Train Acc: 96.52%\n",
      "\t\tTest. Loss: 0.567 |  Val. Acc: 79.42%\n",
      "\tEpoch: 09 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.076 | Train Acc: 97.43%\n",
      "\t\tTest. Loss: 0.624 |  Val. Acc: 79.42%\n",
      "\tEpoch: 10 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.056 | Train Acc: 98.38%\n",
      "\t\tTest. Loss: 0.721 |  Val. Acc: 78.80%\n",
      "============== last test accuracy: 0.8002006567042806\n",
      "\n",
      "kfold 6\n",
      "\tEpoch: 01 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.591 | Train Acc: 67.72%\n",
      "\t\tTest. Loss: 0.454 |  Val. Acc: 78.78%\n",
      "\tEpoch: 02 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.479 | Train Acc: 76.89%\n",
      "\t\tTest. Loss: 0.451 |  Val. Acc: 78.66%\n",
      "\tEpoch: 03 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.408 | Train Acc: 81.61%\n",
      "\t\tTest. Loss: 0.415 |  Val. Acc: 82.29%\n",
      "\tEpoch: 04 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.340 | Train Acc: 85.06%\n",
      "\t\tTest. Loss: 0.408 |  Val. Acc: 82.11%\n",
      "\tEpoch: 05 | Epoch Time: 1m 20s\n",
      "\t\tTrain Loss: 0.285 | Train Acc: 88.14%\n",
      "\t\tTest. Loss: 0.416 |  Val. Acc: 82.19%\n",
      "\tEpoch: 06 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.208 | Train Acc: 91.78%\n",
      "\t\tTest. Loss: 0.434 |  Val. Acc: 82.71%\n",
      "\tEpoch: 07 | Epoch Time: 1m 19s\n",
      "\t\tTrain Loss: 0.162 | Train Acc: 94.01%\n",
      "\t\tTest. Loss: 0.452 |  Val. Acc: 81.71%\n",
      "\tEpoch: 08 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.122 | Train Acc: 95.50%\n",
      "\t\tTest. Loss: 0.728 |  Val. Acc: 75.86%\n",
      "\tEpoch: 09 | Epoch Time: 1m 21s\n",
      "\t\tTrain Loss: 0.076 | Train Acc: 97.50%\n",
      "\t\tTest. Loss: 0.546 |  Val. Acc: 81.71%\n",
      "\tEpoch: 10 | Epoch Time: 1m 18s\n",
      "\t\tTrain Loss: 0.046 | Train Acc: 98.61%\n",
      "\t\tTest. Loss: 1.011 |  Val. Acc: 74.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== last test accuracy: 0.8269696973619007\n",
      "\n",
      "kfold 7\n",
      "\tEpoch: 01 | Epoch Time: 1m 6s\n",
      "\t\tTrain Loss: 0.590 | Train Acc: 67.70%\n",
      "\t\tTest. Loss: 0.510 |  Val. Acc: 73.79%\n",
      "\tEpoch: 02 | Epoch Time: 0m 58s\n",
      "\t\tTrain Loss: 0.475 | Train Acc: 77.51%\n",
      "\t\tTest. Loss: 0.441 |  Val. Acc: 78.78%\n",
      "\tEpoch: 03 | Epoch Time: 0m 57s\n",
      "\t\tTrain Loss: 0.407 | Train Acc: 81.75%\n",
      "\t\tTest. Loss: 0.447 |  Val. Acc: 76.83%\n",
      "\tEpoch: 04 | Epoch Time: 1m 0s\n",
      "\t\tTrain Loss: 0.338 | Train Acc: 85.19%\n",
      "\t\tTest. Loss: 0.454 |  Val. Acc: 78.87%\n",
      "\tEpoch: 05 | Epoch Time: 0m 58s\n",
      "\t\tTrain Loss: 0.271 | Train Acc: 88.59%\n",
      "\t\tTest. Loss: 0.453 |  Val. Acc: 78.40%\n",
      "\tEpoch: 06 | Epoch Time: 0m 58s\n",
      "\t\tTrain Loss: 0.213 | Train Acc: 91.19%\n",
      "\t\tTest. Loss: 0.489 |  Val. Acc: 79.63%\n",
      "\tEpoch: 07 | Epoch Time: 0m 57s\n",
      "\t\tTrain Loss: 0.149 | Train Acc: 94.31%\n",
      "\t\tTest. Loss: 0.486 |  Val. Acc: 78.93%\n",
      "\tEpoch: 08 | Epoch Time: 0m 58s\n",
      "\t\tTrain Loss: 0.100 | Train Acc: 96.53%\n",
      "\t\tTest. Loss: 0.552 |  Val. Acc: 80.16%\n",
      "\tEpoch: 09 | Epoch Time: 0m 59s\n",
      "\t\tTrain Loss: 0.077 | Train Acc: 97.42%\n",
      "\t\tTest. Loss: 0.588 |  Val. Acc: 78.22%\n",
      "\tEpoch: 10 | Epoch Time: 0m 57s\n",
      "\t\tTrain Loss: 0.051 | Train Acc: 98.38%\n",
      "\t\tTest. Loss: 0.622 |  Val. Acc: 79.27%\n",
      "============== last test accuracy: 0.8016148987023727\n",
      "\n",
      "kfold 8\n",
      "\tEpoch: 01 | Epoch Time: 0m 57s\n",
      "\t\tTrain Loss: 0.589 | Train Acc: 67.39%\n",
      "\t\tTest. Loss: 0.519 |  Val. Acc: 73.30%\n",
      "\tEpoch: 02 | Epoch Time: 0m 54s\n",
      "\t\tTrain Loss: 0.475 | Train Acc: 77.08%\n",
      "\t\tTest. Loss: 0.455 |  Val. Acc: 78.11%\n",
      "\tEpoch: 03 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.402 | Train Acc: 80.99%\n",
      "\t\tTest. Loss: 0.439 |  Val. Acc: 79.01%\n",
      "\tEpoch: 04 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.336 | Train Acc: 85.17%\n",
      "\t\tTest. Loss: 0.524 |  Val. Acc: 75.29%\n",
      "\tEpoch: 05 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.275 | Train Acc: 88.84%\n",
      "\t\tTest. Loss: 0.509 |  Val. Acc: 77.93%\n",
      "\tEpoch: 06 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.205 | Train Acc: 91.92%\n",
      "\t\tTest. Loss: 0.694 |  Val. Acc: 74.95%\n",
      "\tEpoch: 07 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.159 | Train Acc: 93.92%\n",
      "\t\tTest. Loss: 0.592 |  Val. Acc: 76.40%\n",
      "\tEpoch: 08 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.101 | Train Acc: 96.34%\n",
      "\t\tTest. Loss: 0.643 |  Val. Acc: 78.76%\n",
      "\tEpoch: 09 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.066 | Train Acc: 97.87%\n",
      "\t\tTest. Loss: 0.651 |  Val. Acc: 80.19%\n",
      "\tEpoch: 10 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.057 | Train Acc: 98.14%\n",
      "\t\tTest. Loss: 0.657 |  Val. Acc: 79.48%\n",
      "============== last test accuracy: 0.7983957149765708\n",
      "\n",
      "kfold 9\n",
      "\tEpoch: 01 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.591 | Train Acc: 66.78%\n",
      "\t\tTest. Loss: 0.601 |  Val. Acc: 67.18%\n",
      "\tEpoch: 02 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.467 | Train Acc: 77.79%\n",
      "\t\tTest. Loss: 0.486 |  Val. Acc: 76.65%\n",
      "\tEpoch: 03 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.403 | Train Acc: 81.85%\n",
      "\t\tTest. Loss: 0.500 |  Val. Acc: 76.98%\n",
      "\tEpoch: 04 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.345 | Train Acc: 84.99%\n",
      "\t\tTest. Loss: 0.508 |  Val. Acc: 75.93%\n",
      "\tEpoch: 05 | Epoch Time: 0m 53s\n",
      "\t\tTrain Loss: 0.274 | Train Acc: 88.22%\n",
      "\t\tTest. Loss: 0.531 |  Val. Acc: 76.49%\n",
      "\tEpoch: 06 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.210 | Train Acc: 91.69%\n",
      "\t\tTest. Loss: 0.582 |  Val. Acc: 77.63%\n",
      "\tEpoch: 07 | Epoch Time: 0m 54s\n",
      "\t\tTrain Loss: 0.149 | Train Acc: 94.62%\n",
      "\t\tTest. Loss: 0.644 |  Val. Acc: 76.88%\n",
      "\tEpoch: 08 | Epoch Time: 0m 52s\n",
      "\t\tTrain Loss: 0.110 | Train Acc: 96.15%\n",
      "\t\tTest. Loss: 0.704 |  Val. Acc: 76.30%\n",
      "\tEpoch: 09 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.072 | Train Acc: 97.77%\n",
      "\t\tTest. Loss: 0.684 |  Val. Acc: 76.81%\n",
      "\tEpoch: 10 | Epoch Time: 0m 51s\n",
      "\t\tTrain Loss: 0.065 | Train Acc: 97.87%\n",
      "\t\tTest. Loss: 0.729 |  Val. Acc: 77.51%\n",
      "============== last test accuracy: 0.7775842036519732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kfold in range(10):\n",
    "    # make datasets\n",
    "    train_path = train_paths[kfold]\n",
    "    val_path = val_paths[kfold]\n",
    "    train_data = TabularDataset(path= train_path, skip_header = True,\n",
    "        format='csv', fields=[('label', LABEL), ('text', TEXT)])\n",
    "    test_data = TabularDataset(path= val_path, skip_header = True,\n",
    "        format='csv', fields=[('label', LABEL), ('text', TEXT)])\n",
    "\n",
    "    TEXT.build_vocab(train_data, vectors =vectors)\n",
    "    LABEL.build_vocab(train_data) \n",
    "    \n",
    "    pretrained_embeddings = torch.FloatTensor(TEXT.vocab.vectors)\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "    pretrained_embeddings[PAD_IDX]= torch.zeros(EMBEDDING_DIM)\n",
    "    pretrained_embeddings[UNK_IDX] = torch.distributions.Uniform(-0.25, +0.25).sample((EMBEDDING_DIM,))\n",
    "\n",
    "    # make iterators\n",
    "    train_iterator,  test_iterator = BucketIterator.splits(\n",
    "        (train_data, test_data), \n",
    "        batch_size = BATCH_SIZE, \n",
    "        device = device, sort=False, shuffle = True)\n",
    "    \n",
    "    # define a model\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "\n",
    "    model = CNN1d(pretrained_embeddings, INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "    optimizer = optim.Adadelta(model.parameters(), rho=0.95)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # train\n",
    "    best_test_acc = -float('inf')\n",
    "    model_name= './model/model_ft' + str(kfold) + '.pt'\n",
    "    print('kfold', kfold)\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "\n",
    "        \n",
    "        print(f'\\tEpoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\t\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t\\tTest. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')\n",
    "    \n",
    "\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    test_acc_lists.append(test_acc)\n",
    "    print(f'============== last test accuracy: {test_acc}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 10 - fold test accuracy ==============\n",
      "Mean acc 80.19%\n",
      "[0.7754545374350115, 0.8145454580133612, 0.8272727213122628, 0.7871957648368109, 0.8094197267835791, 0.8002006567042806, 0.8269696973619007, 0.8016148987023727, 0.7983957149765708, 0.7775842036519732]\n"
     ]
    }
   ],
   "source": [
    "print('============== 10 - fold test accuracy ==============')\n",
    "print(f'Mean acc {np.mean(test_acc_lists)  * 100 :.2f}%')\n",
    "print(test_acc_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
